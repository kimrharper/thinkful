{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTES__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function for a linear regression model $y_i = \\alpha + \\beta x_i$ is:\n",
    "\n",
    "$$\\frac1{n}\\sum_{i=1}^n(y_i-(\\alpha + \\beta x_i))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha + \\beta x_i$ is the prediction of the model $\\alpha + \\beta x$ for predictors $x_i$, $y_i$ is the actual outcome value, and $n$ is the number of distances being summed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our two-parameter regression line model, the derivatives are:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\alpha} =\\frac2n \\sum_{i=1}^n - (y^i-(\\alpha + \\beta x_i) )$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\beta} =\\frac2n \\sum_{i=1}^n - x_i(y^i-(\\alpha + \\beta x_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SAMPLE CODE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients from sklearn: \n",
      " [[1.97548841]]\n",
      "\n",
      "Intercept from sklearn: \n",
      " [0.5009911]\n",
      "Iterations until difference between errors is 0.001: 206\n",
      "\n",
      "Coefficients from gradient descent algorithm: \n",
      " 1.7899875617824543\n",
      "\n",
      "Intercept from gradient descent algorithm: \n",
      " 0.43036091443048985\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1cb560b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Cost function for the linear regression that we will try to optimize.\n",
    "def LR_cost_function (alpha, beta, x, y):\n",
    "    '''Return the cost for a given line and data.\n",
    "    \n",
    "    Alpha and beta are the coeficients that describe the fit line line, while\n",
    "    x and y are lists or arrays with the x and y value of each data point.\n",
    "    '''\n",
    "    error = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        point_error = (y[i] - (alpha + beta * x[i])) ** 2\n",
    "        error += point_error\n",
    "    return error / n\n",
    "\n",
    "\n",
    "# Function we'll call each iteration (or step) of the gradient algorithm.\n",
    "def step (alpha_cur, beta_cur, learning_rate, x, y):\n",
    "    '''Move downhill from a current cost function to a new, more optimal one.'''\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        # Partial derivative of the intercept.\n",
    "        point_alpha = -(2 / n) * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        alpha += point_alpha\n",
    "        \n",
    "        # Partial derivative of the slope.\n",
    "        point_beta = -(2 / n) * x[i] * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        beta += point_beta\n",
    "        \n",
    "    new_alpha = alpha_cur - learning_rate * alpha \n",
    "    new_beta = beta_cur - learning_rate * beta\n",
    "    return [new_alpha, new_beta]\n",
    "\n",
    "# These constants correspond to the decision-points described above.\n",
    "# How many steps to take.\n",
    "stop = 1000\n",
    "\n",
    "# How far to move with each step.\n",
    "learning_rate = .005\n",
    "\n",
    "# Starting values for intercept and slope \n",
    "alpha_start = 0\n",
    "beta_start = 0\n",
    "\n",
    "# Time to make some data!\n",
    "x = np.random.normal(0, 1, 100)\n",
    "y = x * 2 + np.random.sample(100)\n",
    "\n",
    "# Fit an true minimum regression using solved equations.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "print('\\nCoefficients from sklearn: \\n', regr.coef_)\n",
    "print('\\nIntercept from sklearn: \\n', regr.intercept_)\n",
    "\n",
    "\n",
    "# Now fit an iteratively optimized regression using your custom gradient\n",
    "# descent algorithm.\n",
    "\n",
    "# Storing each iteration to inspect later.\n",
    "all_error=[]\n",
    "\n",
    "# Provide starting values.\n",
    "alpha = alpha_start\n",
    "beta = beta_start\n",
    "\n",
    "\n",
    "#Run the algorithm.\n",
    "errorprev = 0\n",
    "\n",
    "for iter in range(stop):\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Take a step, assigning the results of our step function to feed into\n",
    "    # the next step.\n",
    "    alpha, beta = step(alpha, beta, learning_rate, x, y)\n",
    "    \n",
    "    # Calculate the error.\n",
    "    error = LR_cost_function(alpha, beta, x, y)\n",
    "    \n",
    "    if abs(error - errorprev) < 0.001:\n",
    "        print(\"Iterations until difference between errors is 0.001: {}\".format(iter))\n",
    "        break\n",
    "        \n",
    "    errorprev = error\n",
    "    \n",
    "    # Store the error to inspect later.\n",
    "    all_error.append(error)\n",
    "\n",
    "    \n",
    "print('\\nCoefficients from gradient descent algorithm: \\n', beta)\n",
    "print('\\nIntercept from gradient descent algorithm: \\n', alpha)\n",
    "\n",
    "plt.plot(all_error, 'o', ms=.4)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error scores for each iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
