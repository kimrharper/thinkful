{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><strong>Capstone #3:</strong> <span style=\"color:darkred\">Supervised Learning</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:darkred\">__Part 1: Data Exploration__ https://github.com/kimrharper/thinkful/blob/master/unit3/unit3-capstone-exploration.ipynb </span><br><br><span style=\"color:darkred\">__Part 2: Models__ https://github.com/kimrharper/thinkful/blob/master/unit3/unit3-capstone-models.ipynb </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkred\">Part 1: </span><span style=\"color:darkblue\">L1 Prediction from ELL Writing Samples</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Ryan Harper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#ov'>Overview</a><br>\n",
    "<a href='#exp'>Experiment</a><br>\n",
    "<a href='#sec1'>1. Cleaning Data</a><br>\n",
    "<a href='#sec2'>2. Exploring the Data</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ov\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">Overview</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Source:__\n",
    "> http://lang-8.com/ [scraped with Beautiful Soup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](../data/language/lang8.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary:__\n",
    "> In my previous profession, I have been teaching English to a diverse range of students of all ages, language background, and country origin. During my professional development, I started to observe that different students with different L1s (1st Language) tended to display different patterns of communication that appeared to have some connection to either education in their country of origin or a connection to the linguistic structure of their first language. Different ELL (English Language Learners) needed to focus on different aspects of the English language depending on their background. The purpose of this project is to use a large number of blog posts from a language practicing website and explore whether or not the L1 has any significant impact on the blog writing style of the English learner.<br><br>Part 1: Explore the data to find any noteworthy trends in linguistic structure: <ol><li> vocabulary (word freq, collocations, and cognates) <li>syntax (sentence structure)<li>grammar (i.e. grammar complexity of sentences) <li>errors (types of errors) <li> parts of speech (NLTK Abbreviations: https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/)</ol><br>Part 2: Use linguistic trends to determine whether or not a learner's first language can be predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variables:__\n",
    ">__id:__ _User ID_<br>\n",
    "__time:__ _Time the blog post was scraped (in order of user posted time)_ <br>\n",
    "__title:__ _Title of the blog post_<br>\n",
    "__content:__ _The blog post_<br>\n",
    "__language:__ _User's self-reported first language_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">Experiment</span> <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hypothesis:__ \n",
    "> L1 (first language) experience and academic environment influences ELLs' (English Language Learners') writing style. The L1 of ELLs can be predicted by looking at English blog posts and identifying patterns unique to their L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations:__\n",
    "><li> --<li>--<li>--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Method:__\n",
    "> Using multiple different models. The aim of this project is to explore how different models can handle the data (target and features) and to see what information can be gained from using multiple different models. Ultimately, the goal is to determine which models are appropriate for a binary (discrete) target with features that are both qualitative (discrete) and quantitative (ranked/continuous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.anc.org/data/anc-second-release/frequency-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">1. Cleaning the Data</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import brown\n",
    "# nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iPython/Jupyter Notebook\n",
    "import time\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "from IPython.display import Image\n",
    "\n",
    "# Data processing\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import plotly as plo\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, median_test, f_oneway\n",
    "\n",
    "# NLP\n",
    "import textblob\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import difflib\n",
    "from string import punctuation\n",
    "\n",
    "# import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and close files\n",
    "def get_text(link):\n",
    "    with open(link) as f:\n",
    "        output = f.read()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Settings and Imports\n",
    "%pylab\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17141 entries, 0 to 17140\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0    17141 non-null int64\n",
      "id            17141 non-null int64\n",
      "time          17141 non-null object\n",
      "title         17141 non-null object\n",
      "content       17141 non-null object\n",
      "language      17141 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 803.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "blog = pd.read_csv('../data/language/blogdata-reduced.csv')\n",
    "blog.info()\n",
    "\n",
    "# POS Table for reference\n",
    "poscv = pd.read_csv('../data/pos.csv')\n",
    "poscv = poscv.iloc[0:17]\n",
    "poscv.columns = ['Set1','Set 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "blog = pd.read_csv('../data/language/blogdata-reduced.csv')\n",
    "\n",
    "# Clean Data\n",
    "del blog['Unnamed: 0']\n",
    "blog.language = blog.language.mask(blog.language == 'Mandarin', 'Traditional Chinese').replace(['Persian', 'Arabic',\n",
    "        'Bulgarian', 'Swedish', 'Slovenian', 'Slovak', 'Malay', 'Turkish','Romanian', 'Czech', 'Danish', 'Vietnamese',\n",
    "        'Norwegian','Serbian','Other language','Lithuanian', 'Ukrainian', 'Finnish','Estonian','Bengali','Russian', \n",
    "        'Spanish','French', 'German', 'Cantonese','Mongolian', 'Tagalog', 'Polish', 'Dutch','Italian', 'Portuguese(Brazil)', \n",
    "        'Thai', 'Indonesian', 'Cantonese','Urdu', 'Hungarian'], np.nan)\n",
    "blog = blog.dropna().sample(frac=1)\n",
    "\n",
    "del blog['title']\n",
    "del blog['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15724 entries, 11020 to 8201\n",
      "Columns: 3 entries, id to language\n",
      "dtypes: int64(1), object(2)"
     ]
    }
   ],
   "source": [
    "blog.info(verbose=False, memory_usage=False,null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>3218</td>\n",
       "      <td>Hello, this is Wasabi from Japan.  This mornin...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>605</td>\n",
       "      <td>when we talk about Fukuoka city, sometimes cal...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14959</th>\n",
       "      <td>4410</td>\n",
       "      <td>I think Sumo is different from other sports. S...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16610</th>\n",
       "      <td>4905</td>\n",
       "      <td>Our office is located in Shinjuku, Tokyo-metro...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>1117</td>\n",
       "      <td>Hi, this is my first time to visit this websit...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            content  language\n",
       "11020  3218  Hello, this is Wasabi from Japan.  This mornin...  Japanese\n",
       "2271    605  when we talk about Fukuoka city, sometimes cal...  Japanese\n",
       "14959  4410  I think Sumo is different from other sports. S...  Japanese\n",
       "16610  4905  Our office is located in Shinjuku, Tokyo-metro...  Japanese\n",
       "4610   1117  Hi, this is my first time to visit this websit...  Japanese"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirmation that there are no more null values\n",
    "blog.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lettercheck(val):\n",
    "    reLetters = re.compile('[^a-zA-Z]')\n",
    "    onlyletters = reLetters.sub('', val)\n",
    "    return len(onlyletters)/len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Blogs with less than 70% letter percentage: 1491\n"
     ]
    }
   ],
   "source": [
    "blog['letters_per'] = blog.content.apply(lettercheck)\n",
    "print('Removing Blogs with less than 70% letter percentage: {}'.format(blog.loc[blog['letters_per'] <= .7].content.count()))\n",
    "blog = blog.loc[blog['letters_per'] > .7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14233 entries, 11020 to 8201\n",
      "Data columns (total 4 columns):\n",
      "id             14233 non-null int64\n",
      "content        14233 non-null object\n",
      "language       14233 non-null object\n",
      "letters_per    14233 non-null float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 556.0+ KB\n"
     ]
    }
   ],
   "source": [
    "blog.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">2. Exploring the Data</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = list(blog.language.value_counts().values)\n",
    "languages = list(blog.language.value_counts().index)\n",
    "plt.figure(figsize(6,4))\n",
    "plt.bar(languages,vals,edgecolor='black')\n",
    "plt.title('Blogs by L1 Count')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts by 'Native' English Speakers: 69\n"
     ]
    }
   ],
   "source": [
    "print(\"Posts by 'Native' English Speakers: {}\".format(blog.id.loc[blog.language == 'English'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nlp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">NLP: Spell Check, Tokenization, Collocations, Parts of Speech, and Syntax</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Word Level Ranking__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCI_WORDS = pd.read_csv('../data/language/ANC-written-count.txt', \n",
    "                         sep='\\t', \n",
    "                         encoding='latin-1', \n",
    "                         names=['word','stem','pos','freq'],header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ANCI_WORDS['word'].values\n",
    "b = ANCI_WORDS['freq'].values\n",
    "word_freq = list(zip(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_words_dict = {}\n",
    "i = 0\n",
    "\n",
    "for w in word_freq:\n",
    "    i = i + 1\n",
    "    \n",
    "    if w[0] not in full_words_dict:\n",
    "        full_words_dict[w[0]] = w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_dict = {}\n",
    "i = 0\n",
    "\n",
    "for w in word_freq:\n",
    "    i = i + 1\n",
    "    \n",
    "    if w[0] not in words_dict:\n",
    "        if i < 500:\n",
    "            words_dict[w[0]] = 1\n",
    "        elif (i >= 500) & (i < 5000):\n",
    "            words_dict[w[0]] = 2\n",
    "        elif (i >= 5000) & (i < 10000):\n",
    "            words_dict[w[0]] = 3\n",
    "        elif (i >= 5000) & (i < 20000):\n",
    "            words_dict[w[0]] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_rating(l):\n",
    "    score = 0\n",
    "    c=0\n",
    "    for w in l:\n",
    "        if w in words_dict:\n",
    "            c = c + 1\n",
    "            score = score + words_dict[w]\n",
    "    if c == 0:\n",
    "        c=1\n",
    "    return score / c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_freq_rating(l):\n",
    "    score = 0\n",
    "    c=0\n",
    "    for w in l:\n",
    "        if w in full_words_dict:\n",
    "            c = c + 1\n",
    "            score = score + full_words_dict[w]\n",
    "    if c == 0:\n",
    "        c=1\n",
    "    return score / c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TextBlob__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 6.09 ms, total: 224 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blob = blog.content.apply(lambda val: textblob.TextBlob(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posbigram(val):\n",
    "    l = []\n",
    "    bigramlist = []\n",
    "    \n",
    "    for s in val.sentences:\n",
    "        ns = textblob.TextBlob(str(s)).tags\n",
    "        l = [v[1] for v in ns]\n",
    "        bigrm = list(nltk.bigrams(l))\n",
    "        \n",
    "        for bigram in bigrm:\n",
    "            bigramlist.append('-'.join(bigram))\n",
    "        \n",
    "    return bigramlist\n",
    "\n",
    "def postrigram(val):\n",
    "    l = []\n",
    "    trigramlist = []\n",
    "    \n",
    "    for s in val.sentences:\n",
    "        ns = textblob.TextBlob(str(s)).tags\n",
    "        l = [v[1] for v in ns]\n",
    "        trigrm = list(nltk.trigrams(l))\n",
    "        \n",
    "        for trigram in trigrm:\n",
    "            trigramlist.append('-'.join(trigram))\n",
    "        \n",
    "    return trigramlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/api.py:322: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/Users/ryan/nltk_data/corpora/brown/cats.txt'>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 12s, sys: 10.8 s, total: 3min 23s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blog['wc'] = blob.apply(lambda val: len(val.words))\n",
    "blog['sc'] = blob.apply(lambda val: len(val.sentences))\n",
    "blog['tokens'] = blob.apply(lambda val: [w.lower() for w in val.words])\n",
    "blog['pos'] = blob.apply(lambda val: [v[1] for v in val.tags])\n",
    "blog['nns'] = blob.apply(lambda val: val.noun_phrases)\n",
    "blog['sent_pol'] = blob.apply(lambda val: val.sentiment[0])\n",
    "blog['sent_subj'] = blob.apply(lambda val: val.sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda3/lib/python3.6/site-packages/nltk/util.py:491: DeprecationWarning:\n",
      "\n",
      "generator 'ngrams' raised StopIteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 2.04 s, total: 1min 50s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blog['pos2'] = blob.apply(posbigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda3/lib/python3.6/site-packages/nltk/util.py:510: DeprecationWarning:\n",
      "\n",
      "generator 'ngrams' raised StopIteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 2.25 s, total: 1min 51s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blog['pos3'] = blob.apply(postrigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog['freq_score'] = blob.apply(lambda val: freq_rating(val.words))\n",
    "blog['full_freq_score'] = blob.apply(lambda val: full_freq_rating(val.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Cleaning Round 2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog = blog[blog['wc'] >= 4]\n",
    "blog = blog[blog['full_freq_score'] > 1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Backup File__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "blog.to_csv('processed_blog_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">2. Feature Processing:</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_count_df(df,col,name,keep=[],):\n",
    "    colset = set(df[col].sum())\n",
    "    finalsetlist = []\n",
    "    if len(keep) > 0:\n",
    "        colset = [k for k in keep if k in colset]\n",
    "    \n",
    "    for c in colset:\n",
    "        colname = name+'_'+str(c)\n",
    "        df[colname] = df[col].apply(lambda val: val.count(c))\n",
    "        \n",
    "        if df[colname].sum() < 1:\n",
    "            del df[colname]\n",
    "        else:\n",
    "            finalsetlist.append(colname)\n",
    "        \n",
    "    print('Created dummy counter for {} features'.format(name))\n",
    "        \n",
    "    return finalsetlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters1 = []\n",
    "for let in 'abcdefghijklmnopqrstuvwxyz':\n",
    "    name = 'let1_'+let\n",
    "    blog[name] = blog.tokens.apply(lambda val: ''.join(val).count(let))\n",
    "    letters1.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.3 s, sys: 441 ms, total: 38.7 s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alphabet = list('abcdefghijklmnopqrstuvwxyz')\n",
    "letters2 = []\n",
    "for let in alphabet:\n",
    "    for let2 in alphabet:\n",
    "        letters2.append(let+let2)\n",
    "\n",
    "letters2name = []        \n",
    "for let in letters2:\n",
    "    name = 'let2_'+let\n",
    "    blog[name] = blog.tokens.apply(lambda val: ' '.join(val).count(let))\n",
    "    if blog[name].sum() < 10:\n",
    "        del blog[name]\n",
    "    else:\n",
    "        letters2name.append(name)\n",
    "        \n",
    "letters2 = letters2name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ANCI_WORDS.pos.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy counter for prp features\n",
      "CPU times: user 1min 54s, sys: 31 s, total: 2min 25s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prplist = list(ANCI_WORDS['word'][ANCI_WORDS.pos == 'PRP'])\n",
    "pronouns = create_dummy_count_df(blog,'tokens','prp',prplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy counter for cc features\n",
      "CPU times: user 1min 53s, sys: 31.3 s, total: 2min 25s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cclist = list(ANCI_WORDS['word'][ANCI_WORDS.pos == 'CC'])\n",
    "coordinators = create_dummy_count_df(blog,'tokens','cc',cclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy counter for prep features\n",
      "CPU times: user 1min 55s, sys: 30.8 s, total: 2min 26s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inlist = list(ANCI_WORDS['word'][ANCI_WORDS.pos == 'IN'])\n",
    "preposition = create_dummy_count_df(blog,'tokens','prep',inlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy counter for adv features\n",
      "CPU times: user 1min 47s, sys: 29.3 s, total: 2min 16s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "adverblist = list(ANCI_WORDS['word'][ANCI_WORDS.pos == 'RB'])[0:50]\n",
    "adverb = create_dummy_count_df(blog,'tokens','adv',adverblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy counter for pos2 features\n",
      "Created dummy counter for pos1 features\n",
      "CPU times: user 3min 12s, sys: 54.9 s, total: 4min 7s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pos2 = create_dummy_count_df(blog,'pos2','pos2')\n",
    "pos1 = create_dummy_count_df(blog,'pos','pos1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pos3 = create_dummy_count_df(blog,'pos3','pos3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "blog.to_csv('blogfeatures.csv')\n",
    "# features_user.to_csv('userblogfeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bar Plots__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.set()\n",
    "letters1.groupby('language').mean().reset_index().set_index('language').T.plot(kind='bar', stacked=False,figsize=(20,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.set()\n",
    "letters2.groupby('language').mean().iloc[:,500:549].reset_index().set_index('language').T.plot(kind='bar', stacked=False,figsize=(20,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lang = list(blog.language.unique())\n",
    "\n",
    "def count_vals_df(df,col):\n",
    "    return pd.DataFrame(data = [Counter(np.concatenate(np.array(df[col][blog.language == l]))) for l in lang], \n",
    "                        index = [l for l in lang]).T.fillna(0).sort_values(by='Japanese',ascending=False)\n",
    "\n",
    "def graphsum(df):\n",
    "    for l in df:\n",
    "        df[l] = df[l]/df[l].sum()\n",
    "    return df\n",
    "\n",
    "def graph_bar(df,name,dim):\n",
    "    graphsum(df).plot.bar(rot=0,figsize=dim)\n",
    "    plt.title(name,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def graph_hbar(df,name,dim):\n",
    "    graphsum(df).plot.barh(rot=0,figsize=dim)\n",
    "    plt.title(name,fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pos2 = count_vals_df(blog,'pos2').iloc[0:25]\n",
    "graph_bar(pos2,'Parts of Speech - Bigrams',(22, 4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for g in [(blog[blog.language == l]) for l in lang]:\n",
    "    sns.kdeplot(g['sent_pol'],g['sent_subj'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_There is a lower English sample count so higher variance is expected._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reject Outliers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import robust\n",
    "\n",
    "def MEDIAN_reject_outliers(data, m=3):\n",
    "    data = data[(data - np.median(data)) < m*robust.mad(data)]\n",
    "    return data[~numpy.isnan(data)].sort_values()\n",
    "\n",
    "\n",
    "def MEAN_reject_outliers(data, m=3):\n",
    "    data = data[abs(data - np.mean(data)) < m*np.std(data)]\n",
    "    return data[~numpy.isnan(data)].sort_values()\n",
    "\n",
    "# lanlenseries = [reject_outliers(blog.char_count[blog.language == l]) for l in list(blog.language.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Analysis Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_features = ['let2_ja', 'pos2_PRP-VBD', 'let2_ko', 'sc', 'wc', 'let2_he', 'let2_ap', 'let2_nw', 'let2_ea', \n",
    "                   'let2_rn', 'let2_yb', 'let2_wh', 'let2_ku', 'let2_el', 'pos2_NN-MD', 'let2_th', 'let2_pa', \n",
    "                   'pos2_CD-NN', 'sent_subj', 'prep_that', 'let2_io', 'pos2_NNS-RB', 'pos2_PRP-CC', 'let2_hq']\n",
    "full_features = import_features + ['language']\n",
    "\n",
    "\n",
    "analysis = blog[full_features]\n",
    "# analysis2 = analysis.groupby(['id','language']).mean()\n",
    "# analysis2.reset_index(inplace=True)\n",
    "# print(\"'Native' English Speaker Count: {}\".format(analysis2.id.loc[analysis2.language == 'English'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot Hist__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_POS Features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = list(blog.language.unique())\n",
    "i = 1\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "for pos in pos1:\n",
    "    plt.subplot(6, 6, i)\n",
    "    i = i + 1\n",
    "    \n",
    "    for g in [MEDIAN_reject_outliers(blog[pos][blog.language == l],3) for l in lang]:\n",
    "        sns.kdeplot(g,legend=None,kernel='gau',shade=True)\n",
    "#         plt.hist(g,alpha=0.8)\n",
    "        plt.title(pos)\n",
    "\n",
    "fig.suptitle('Histograms of POS Features', fontsize=18, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.legend(lang)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in pos1:\n",
    "    p = shapiro(blog[c])[1]\n",
    "    if (p < .05) & (p > 0):\n",
    "        print('{}:\\x1b[92m{}\\x1b[0m'.format(c,p),end='|')\n",
    "    elif p > .05:\n",
    "        print('{}:\\x1b[31m{}\\x1b[0m'.format(c,p),end='|')\n",
    "    else:\n",
    "        print('{}:\\x1b[33m{}\\x1b[0m'.format(c,p),end='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Decision Tree Truncated SVD Features_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 1\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "for pos in import_features:\n",
    "    plt.subplot(6, 6, i)\n",
    "    i = i + 1\n",
    "    \n",
    "    for g in [(blog[pos][blog.language == l]) for l in lang[0:3]]:\n",
    "        sns.kdeplot(g,legend=None,kernel='gau',shade=True)\n",
    "#         plt.hist(g,alpha=0.8)\n",
    "        plt.title(pos)\n",
    "\n",
    "fig.suptitle('Histograms of Important Features (Ranked from Decision Tree)', fontsize=18, y=1.03)\n",
    "plt.tight_layout()\n",
    "plt.legend(lang[0:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in import_features:\n",
    "    p = shapiro(blog[c])[1]\n",
    "    if (p < .05) & (p > 0):\n",
    "        print('{}:\\x1b[92m{}\\x1b[0m'.format(c,p),end='|')\n",
    "    elif p > .05:\n",
    "        print('{}:\\x1b[31m{}\\x1b[0m'.format(c,p),end='|')\n",
    "    else:\n",
    "        print('{}:\\x1b[33m{}\\x1b[0m'.format(c,p),end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['id','content','language','tokens','pos','pos2','pos3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goodlist = []\n",
    "for c in list(blog.columns):\n",
    "    if c not in exclude:\n",
    "\n",
    "        p = shapiro(blog[c])[1]\n",
    "        if (p < .05) & (p > 0):\n",
    "            print('{}:\\x1b[92m{}\\x1b[0m'.format(c,p),end='|')\n",
    "            goodlist.append(c)   \n",
    "        elif p > .05:\n",
    "            print('{}:\\x1b[31m{}\\x1b[0m'.format(c,p),end='|')\n",
    "        else:\n",
    "            pass\n",
    "#             print('{}:\\x1b[33m{}\\x1b[0m'.format(c,p),end='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Correlations (of top features by decision tree importance)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = analysis.corr(); print(corr)\n",
    "i = 1\n",
    "fig=plt.figure(figsize=(22,10))\n",
    "\n",
    "for ind,g in enumerate([(analysis[import_features[0:5]][analysis.language == l]) for l in lang]):\n",
    "    plt.subplot(2, 2, i)\n",
    "    i = i + 1\n",
    "    \n",
    "    corr = g.corr()\n",
    "    sns.heatmap(corr, \n",
    "            xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns,\n",
    "            annot=True)\n",
    "    plt.title(lang[ind])\n",
    "    plt.xticks(rotation='vertical',fontsize = 9)\n",
    "    plt.yticks(rotation='horizontal',fontsize = 7)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:darkblue\">C. Statistical Significance <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mw_test(a,b):\n",
    "    stat,p = mannwhitneyu(a,b, use_continuity=True, alternative=None)\n",
    "    return stat,p\n",
    "\n",
    "def mood_test(a,b,c,d):\n",
    "    stat, p, med, tbl = median_test(a,b,c,d)\n",
    "    return stat,p\n",
    "\n",
    "def f1way_test(a,b,c,d):\n",
    "    f,b = f_oneway(a,b,c,d)\n",
    "    return f,b\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mann Whitney U test (2 Non-Normally Distributed Independent Samples)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Japanese -- Chinese]')\n",
    "\n",
    "for pos in import_features:\n",
    "    g = [MEDIAN_reject_outliers(analysis[pos][analysis.language == l]) for l in lang]\n",
    "    stat,p = mw_test(g[0],g[1])\n",
    "    vals = 'stat={}, p={}'.format(stat,p)\n",
    "    if p < .05:\n",
    "        print('{}:\\x1b[92m{}\\x1b[0m'.format(pos,vals))\n",
    "    else:\n",
    "        print('{}:\\x1b[31m{}\\x1b[0m'.format(pos,vals))\n",
    "poscv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Mood’s Median test (2+ Non-Normally Distributed Independent Samples)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Null Hypothesis:__ Assumes samples are from same 1st language population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in import_features:\n",
    "    g = [(analysis[pos][analysis.language == l]) for l in lang]\n",
    "    \n",
    "    stat,p = mood_test(g[0],g[1],g[2],g[3])\n",
    "    vals = 'stat={}, p={}'.format(stat,p)\n",
    "    if p < .05:\n",
    "        print('{}:\\x1b[92m{}\\x1b[0m'.format(pos,vals))\n",
    "    else:\n",
    "        print('{}:\\x1b[31m{}\\x1b[0m'.format(pos,vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(*blog['language'].isin(lang)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "stat, p, med, tbl = median_test(*blog['language'].isin(lang))\n",
    "print(stat,med)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is less than 5% and disproves the null hypothesis. With regards to error percentage, L1 language samples have different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. One-Way AnovaTest (2+ Normally Distributed Independent Samples)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Null Hypothesis:__ Assumes samples are from same 1st language population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in import_features:\n",
    "    g = [(analysis[pos][analysis.language == l]) for l in lang]\n",
    "    \n",
    "    f,b = f1way_test(g[0],g[1],g[2],g[3])\n",
    "    vals = 'f={}, b={}'.format(f,b)\n",
    "    if b < .05:\n",
    "        print('{}:\\x1b[92m{}\\x1b[0m'.format(pos,vals))\n",
    "    else:\n",
    "        print('{}:\\x1b[31m{}\\x1b[0m'.format(pos,vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is less than 5% and disproves the null hypothesis. L1 samples have different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"output\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
