{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><strong>Capstone #3:</strong> <span style=\"color:darkred\">Supervised Learning</span> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### </span>__Part 1:__ Exploration https://github.com/kimrharper/thinkful/blob/master/unit3/unit3-capstone-exploration.ipynb </span><br><span>__Part 2:__ Analysis https://github.com/kimrharper/thinkful/blob/master/unit3/unit3-capstone-analysis.ipynb </span><br><span>__Part 3:__ Models https://github.com/kimrharper/thinkful/blob/master/unit3/unit3-capstone-models.ipynb </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# <span style=\"color:darkred\">L1 Prediction from ELL Writing Samples</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Part 3: </span><span style=\"color:darkblue\">Models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Ryan Harper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#ov'>Overview</a><br>\n",
    "<a href='#exp'>Experiment</a><br>\n",
    "<a href='#sec1'>1. Models:</a><br>\n",
    "><a href='#seca'>A. LR - Ordinary Least Squares</a><br>\n",
    "<a href='#secb'>B. LR - Logistic Regression</a> <a href='#secb1'> (Lasso)</a> <a href='#secb2'> (Ridge)</a><br>\n",
    "<a href='#secc'>C. NN - K Nearest Neighbors</a><br>\n",
    "<a href='#secd'>D. NN - Naive Bayes</a><br>\n",
    "<a href='#sece'>E. NN - Decision Tree</a><br>\n",
    "<a href='#secf'>F. Ensemble - Random Forest</a><br>\n",
    "\n",
    "<a href='#sec2'>2. Model Comparison</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">1. Models:</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iPython/Jupyter Notebook\n",
    "import time\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "from IPython.display import Image\n",
    "\n",
    "import time\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import plotly as plo\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# NLP\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import difflib\n",
    "\n",
    "# Stats\n",
    "from sklearn.metrics import classification_report, roc_curve,roc_auc_score,accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Preparing Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Decomposition\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "\n",
    "# Models\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB,GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Ensemble\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Visualization\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Features + Target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadf = True\n",
    "if loadf:\n",
    "    features = pd.read_csv('blogfeatures.csv').sample(frac=1.0)\n",
    "    del features['Unnamed: 0']\n",
    "else:\n",
    "    %store -r blog\n",
    "    %store -r keepfeatures\n",
    "    features = blog\n",
    "\n",
    "lang = list(features.language.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features['id']\n",
    "del features['content']\n",
    "del features['pos']\n",
    "del features['pos2']\n",
    "del features['pos3']\n",
    "del features['tokens']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features = features[features['sc']<15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Japanese               9536\n",
       "Traditional Chinese    3407\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set X,Y__ (UNUSED)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = features['language'].values.reshape(-1, 1).ravel()\n",
    "X = features[features.columns[~features.columns.str.contains('language')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select Features:__ Features with biggest differences between L1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bnb_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4847ab00e95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mselectfeatures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bnb_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "selectfeatures = 3\n",
    "if selectfeatures == 1:\n",
    "    nonbinary = ['letters_per','wc','sc','sent_pol','sent_subj','cap_let','punc_count','freq_score','full_freq_score']\n",
    "    best_features = keepfeatures\n",
    "elif selectfeatures == 2:\n",
    "    best_features = features.columns[~features.columns.str.contains('language')]\n",
    "elif selectfeatures == 3:\n",
    "    best_features = bnb_sorted[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Truncated SVD:__ Determine best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdbool = False\n",
    "if svdbool:\n",
    "    svd = TruncatedSVD(n_components=20, n_iter=7, random_state=42)\n",
    "    svd.fit(features[best_features])\n",
    "    # print(svd.explained_variance_ratio_)\n",
    "    # print(svd.explained_variance_ratio_.sum())  \n",
    "    # print(svd.singular_values_)\n",
    "    # svd.get_params\n",
    "    # best_features = [X.columns[i] for i in svd.components_[0].argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split Data to Train/Test__: Even Distribution Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evenly_distributed_test = [60 japanese,60 english, 60 chinese, 60 korean]\n",
    "langlist = []\n",
    "rs=87\n",
    "for l in lang:\n",
    "    print(l)\n",
    "    langlist.append(features[features['language'] == l].sample(n=200, random_state=rs))\n",
    "\n",
    "testset = langlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.concat(testset)\n",
    "y_test = test_data['language'].values.reshape(-1, 1).ravel()\n",
    "X_test = test_data[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data = features[~features.isin(test_data)].dropna()\n",
    "y_train = train_data['language'].values.reshape(-1, 1).ravel()\n",
    "X_train = train_data[best_features]\n",
    "# X_train = svd.transform(train_data[train_data.columns[~train_data.columns.str.contains('language')]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Function for Comparing Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['name','time','total','precision','recall','f1']\n",
    "\n",
    "model_set = pd.DataFrame(columns=cols)\n",
    "models_stored = []\n",
    "pattern = \"%.2f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model,name):\n",
    "    global model_set\n",
    "    m = model\n",
    "    m.fit(X_train, y_train)\n",
    "    start = time.time()\n",
    "\n",
    "    total_score = m.score(X_test,y_test)\n",
    "    pscore = [pattern % i for i in list(metrics.precision_score(y_test, m.predict(X_test),labels=lang,average=None))]\n",
    "    rscore = [pattern % i for i in list(metrics.recall_score(y_test, m.predict(X_test),labels=lang,average=None))]\n",
    "    fscore = [pattern % i for i in list(metrics.f1_score(y_test, m.predict(X_test),labels=lang,average=None))]\n",
    "    end = time.time()\n",
    "    t= pattern % (end - start)\n",
    "    cvs = cross_val_score(m, X_test,y_test)\n",
    "\n",
    "    r = dict(zip(cols,[name,t,total_score,pscore,rscore,fscore]))\n",
    "    print('Check for Overfitting: {}\\n'.format(m.score(X_train,y_train)))\n",
    "    print('Test Score is: {}\\n'.format(total_score))\n",
    "    print(classification_report(y_test, m.predict(X_test)))\n",
    "    print('')\n",
    "    print('Cross Val Score: {} | Avg: {} '.format(cvs,cvs.sum()/len(cvs)))\n",
    "    print('')\n",
    "    \n",
    "    model_set = model_set.append(r,ignore_index=True)\n",
    "    return r,m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seca\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">A. LR - Logistic Regression</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Target is binary so logistic regression will operate on probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lreg_data,lreg = run_model(linear_model.LogisticRegression(),'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_coef = lreg.coef_[0][-20:]\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(range(len(X_train.columns[-20:])), lreg_coef)\n",
    "plt.xticks(range(len(X_train.columns[-20:])), X_train.columns, rotation=60)\n",
    "plt.margins(0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sece\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">E. K Nearest Neighbors</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Can handle discrete values for target <br>Quantitative values are limited (not continuous) and might be problematic for nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "neighbors_data,neighbors = run_model(KNeighborsClassifier(n_neighbors=8),'K Nearest Neighbor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"secf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">F. Naive Bayes - Bernoulli</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bnb_data,bnb = run_model(BernoulliNB(),'Naive Bayes - Bernoulli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectfeatures != 3:\n",
    "    importance = dict(list(zip(X_train.columns,bnb.coef_[0])))\n",
    "    bnb_sorted = sorted(importance, key=importance.get, reverse=True)\n",
    "    %store bnb_sorted\n",
    "\n",
    "    bnb_coef = []\n",
    "    for r in bnb_sorted:\n",
    "        bnb_coef.append(importance[r])\n",
    "\n",
    "    bnb_coef = bnb_coef[::-1]\n",
    "\n",
    "    # Plot the coefficients\n",
    "    plt.figure(figsize=(18,4))\n",
    "    plt.plot(range(len(bnb_coef[0:40])), bnb_coef[0:40])\n",
    "    plt.xticks(range(len(bnb_coef[0:40])), bnb_sorted[0:40], rotation=60)\n",
    "    plt.margins(0.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[print(c) for c in X_train.columns];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"secg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">G. Decision Tree</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt_data,dt = run_model(tree.DecisionTreeClassifier(criterion='entropy',max_depth=4),'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render tree.\n",
    "dot_data = tree.export_graphviz(\n",
    "    dt, \n",
    "    out_file=None,\n",
    "    feature_names=X_train.columns,\n",
    "    label= 'root',\n",
    "    proportion=False,\n",
    "    rounded=True,\n",
    "    class_names=lang,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())\n",
    "\n",
    "graph.write_png('decision_tree.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dimportance = list(zip(best_features,dt.feature_importances_))\n",
    "dimportance = dict(dimportance)\n",
    "a1_sorted_keys = sorted(dimportance, key=dimportance.get, reverse=True)\n",
    "p = []\n",
    "for r in a1_sorted_keys:\n",
    "    if dimportance[r] != 0:\n",
    "        p.append(r)\n",
    "#         print(r, dimportance[r])\n",
    "        \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Good visualization of important features and presentation of entropy weighting_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sech\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">H. Random Forest</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Runs decision tree multiple times for best output <br>Longest processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_data,rf = run_model(ensemble.RandomForestClassifier(n_estimators=150,\n",
    "                                                       criterion='entropy',\n",
    "                                                       max_features=len(X_train.columns),\n",
    "                                                       max_depth=6),'Random Forest')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvs = cross_val_score(rf, X_test, y_test, cv=5)\n",
    "print(cvs.sum()/len(cvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_\n",
    "importance = dict(list(zip(X_train.columns,rf.feature_importances_)))\n",
    "rf_sorted = sorted(importance, key=importance.get, reverse=True)\n",
    "for r in rf_sorted[0:5]:\n",
    "    if importance[r] >0:\n",
    "        print(r, importance[r])\n",
    "print('')\n",
    "%store rf_sorted"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i_tree = 0\n",
    "for tree_in_forest in rf.estimators_:\n",
    "    dot_data = tree.export_graphviz(tree_in_forest, out_file=None,feature_names=X_train.columns,label= 'root',\n",
    "                                    proportion=False,rounded=True,class_names=lang,filled=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    Image(graph.create_png())\n",
    "    graph.write_png('decision_tree'+str(i_tree)+'.png')\n",
    "    i_tree = i_tree+1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sech\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">I. MLPC - Supervised Neural Network</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mlp_data,mlp = run_model(MLPClassifier(hidden_layer_sizes=(400,)),'Neural Network - MLPC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">2. Model Comparison</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_set.columns = ['name','time','total','prec: | JA | CH |','rec: | JA | CH |','f1: | JA | CH |']\n",
    "model_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = model_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
