{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span>Part 1: Exploration <br><a href=\"https://kimrharper.github.io/port3a.html\"> https://kimrharper.github.io/port3a.html</a> </span><br><br><span>Part 2: Analysis <br><a href=\"https://kimrharper.github.io/port3b.html\"> https://kimrharper.github.io/port3b.html</a> </span><br><br><span>Part 3: Models <br><a href=\"https://kimrharper.github.io/port3c.html\"> https://kimrharper.github.io/port3c.html</a> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# <span style=\"color:darkred\">Neural Network Assessment of ELL Blog Writing Samples</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkred\">Part 1: </span><span style=\"color:darkblue\">Exploration</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Ryan Harper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#ov'>Overview</a><br>\n",
    "<a href='#exp'>Experiment</a><br>\n",
    "<a href='#sec1'>1. Cleaning Data</a><br>\n",
    "<a href='#sec2'>2. Exploring the Data</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ov\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">1. Cleaning the Data</span>  <a href='#top'>(top)</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import brown\n",
    "# nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "\n",
    "# iPython/Jupyter Notebook\n",
    "import time\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "from IPython.display import Image\n",
    "\n",
    "# Data processing\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import plotly as plo\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r reduced_blog_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_blog_set.language = pd.Categorical(reduced_blog_set.language)\n",
    "analysis = reduced_blog_set[['word_vector','language']].copy()\n",
    "analysis.language = analysis.language.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create Train/Test X and Y__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(analysis, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.word_vector.tolist())\n",
    "X_train = np.array([x[0] for x in X_train]).astype('float32')\n",
    "y_train = np.array(train.language.tolist())\n",
    "\n",
    "X_test = np.array(test.word_vector.tolist())\n",
    "X_test = np.array([x[0] for x in X_test]).astype('float32')\n",
    "y_test = np.array(test.language.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot encoding)\n",
    "num_classes = 2\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(150,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 1024)              154624    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 680,450\n",
      "Trainable params: 680,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7503 samples, validate on 2502 samples\n",
      "Epoch 1/5\n",
      "7503/7503 [==============================] - 11s 1ms/step - loss: 2.2385 - acc: 0.7044 - val_loss: 0.6637 - val_acc: 0.6239\n",
      "Epoch 2/5\n",
      "7503/7503 [==============================] - 11s 1ms/step - loss: 0.6599 - acc: 0.7309 - val_loss: 0.6024 - val_acc: 0.7490\n",
      "Epoch 3/5\n",
      "7503/7503 [==============================] - 11s 1ms/step - loss: 0.6499 - acc: 0.7389 - val_loss: 0.5847 - val_acc: 0.7538\n",
      "Epoch 4/5\n",
      "7503/7503 [==============================] - 13s 2ms/step - loss: 0.6411 - acc: 0.7360 - val_loss: 0.5971 - val_acc: 0.7538\n",
      "Epoch 5/5\n",
      "7503/7503 [==============================] - 12s 2ms/step - loss: 0.6377 - acc: 0.7365 - val_loss: 0.6469 - val_acc: 0.7534\n",
      "Test loss: 0.6468969269526853\n",
      "Test accuracy: 0.7533972822219062\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.06312193, -0.01786287, -0.08118401, ..., -0.0662653 ,\n",
       "         -0.08820986, -0.1320476 ],\n",
       "        [-0.02204491, -0.08333026,  0.04926576, ..., -0.08227797,\n",
       "         -0.01652156, -0.09789168],\n",
       "        [ 0.09182291, -0.05730353,  0.03972671, ..., -0.17979299,\n",
       "          0.04059052, -0.10582564],\n",
       "        ...,\n",
       "        [ 0.04771955,  0.11490059,  0.04417313, ...,  0.12782656,\n",
       "          0.10084348,  0.08802003],\n",
       "        [ 0.0111557 ,  0.00341724, -0.00908889, ...,  0.11742663,\n",
       "         -0.01136766,  0.04962639],\n",
       "        [-0.07296592,  0.0234004 ,  0.00652357, ...,  0.0204281 ,\n",
       "          0.08196013,  0.06355172]], dtype=float32),\n",
       " array([-0.02213672, -0.11314604,  0.00187487, ..., -0.13122389,\n",
       "        -0.0340157 , -0.11443368], dtype=float32),\n",
       " array([[-0.02225625, -0.04128568, -0.01256624, ...,  0.01576541,\n",
       "          0.03290936,  0.01055476],\n",
       "        [-0.0383021 ,  0.02399304,  0.05266332, ..., -0.025118  ,\n",
       "         -0.00475801,  0.03746352],\n",
       "        [-0.00366795,  0.01168637,  0.07383105, ...,  0.04851911,\n",
       "          0.0052446 , -0.02265409],\n",
       "        ...,\n",
       "        [-0.00215849,  0.0045615 , -0.05170629, ..., -0.03318515,\n",
       "          0.03542047,  0.02974645],\n",
       "        [-0.08468027, -0.06752695,  0.02436825, ..., -0.00950891,\n",
       "         -0.00737041,  0.03500586],\n",
       "        [-0.01480963,  0.03128577, -0.02449404, ...,  0.03324885,\n",
       "          0.02636029, -0.03438731]], dtype=float32),\n",
       " array([-0.01898491, -0.01599117, -0.05159483, ..., -0.02976484,\n",
       "        -0.0116131 , -0.02113164], dtype=float32),\n",
       " array([[ 0.01500826,  0.01558259],\n",
       "        [ 0.05951616,  0.05290798],\n",
       "        [ 0.01358582,  0.06121098],\n",
       "        ...,\n",
       "        [-0.027075  , -0.01046624],\n",
       "        [-0.01966711,  0.03009556],\n",
       "        [-0.00457994, -0.01698585]], dtype=float32),\n",
       " array([ 0.05450512, -0.05450483], dtype=float32)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
