{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/\n",
    "\n",
    "https://www.quora.com/What-is-meant-by-feature-maps-in-convolutional-neural-networks\n",
    "\n",
    "http://www.evanmiller.org/bayesian-average-ratings.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/34033785/normalize-values-in-dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ranking Data:\n",
    "data.groupby('user').transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mixture Models - Compute Models (n_count)\n",
    "Count Log Likelihood of each\n",
    "\n",
    "Akaike Information Criterion\n",
    "2*n_features - 2*maxlikelihood_est\n",
    "Bayesian Information Criterion\n",
    "ln(n_samples)*n_features-2*maxlikelihood_est\n",
    "\n",
    "Normalize Ratings Data by Rater\n",
    "Compute Weighted Bayesian Average\n",
    "\n",
    "V-measure (determining goodness of clusters) - Similar to precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Session I:\n",
    "    ✓ Explore data and build basic model\n",
    "        ✓ Hist of # per char per comment\n",
    "        ✓ Hist of scores\n",
    "        X Does comment contain 'great'\n",
    "\n",
    "Session II:\n",
    "    Refine basic model and write up\n",
    "\n",
    "Session III:\n",
    "    Try more refined modeling\n",
    "    \n",
    "Session IV:\n",
    "    Write up better model, gonutz\n",
    "\n",
    "Session V:\n",
    "    Polish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import textblob\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels import robust\n",
    "from string import punctuation\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# for mac only: frog,blow,funk,glass,tink,submarine,purr,sosumi\n",
    "def beep(audio): \n",
    "    os.system('afplay /System/Library/Sounds/' + audio +'.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Add Basic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv('../data/boardgame/boardgame-comments-english.csv').sample(frac=.2)\n",
    "review.columns = 'reviewer_id', 'game_id', 'rating', 'comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = review.comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Round Ratings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RATINGS ADJUSTMENT: ceiling >= .5 [or] floor < .5\n",
    "review['rating'] = review.rating.apply(round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Show ReviewerID and GameID Counts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>89758</td>\n",
       "      <td>39856</td>\n",
       "      <td>8</td>\n",
       "      <td>First Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526222</th>\n",
       "      <td>47523</td>\n",
       "      <td>70323</td>\n",
       "      <td>8</td>\n",
       "      <td>Always entertaining!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31250</th>\n",
       "      <td>30805</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>Cute game of path-building. You're trying to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776264</th>\n",
       "      <td>191795</td>\n",
       "      <td>146021</td>\n",
       "      <td>3</td>\n",
       "      <td>Not my piece of cake. Much randomness and litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687018</th>\n",
       "      <td>51799</td>\n",
       "      <td>3076</td>\n",
       "      <td>8</td>\n",
       "      <td>I haven't played this game too much. But the t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewer_id  game_id  rating  \\\n",
       "1229          89758    39856       8   \n",
       "526222        47523    70323       8   \n",
       "31250         30805       10       6   \n",
       "776264       191795   146021       3   \n",
       "687018        51799     3076       8   \n",
       "\n",
       "                                                  comment  \n",
       "1229                                       First Edition   \n",
       "526222                               Always entertaining!  \n",
       "31250   Cute game of path-building. You're trying to h...  \n",
       "776264  Not my piece of cake. Much randomness and litt...  \n",
       "687018  I haven't played this game too much. But the t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822      2362\n",
       "13       2196\n",
       "30549    1900\n",
       "Name: game_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamereview = review.groupby('reviewer_id')\n",
    "# dflist = []\n",
    "# for r in gamereview:\n",
    "#     dflist.append(r[1])  \n",
    "review.game_id.value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del review['game_id']\n",
    "del review['reviewer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating     False\n",
       "comment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "review.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __2. Ratings Distribution__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, normalize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ratings = np.array(review['rating']).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y_normalized = normalize(ratings, norm='l2')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A. SK Learn: Normalize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.distplot(ratings);\n",
    "plt.show()\n",
    "sns.distplot(Y_normalized);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A. Bayesian Average_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "global constant normalization\n",
    "bayesian average rating with regression prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "normalize with bayesian average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Min/Max Transform (Sklearn Preprocessing Doesn't Apply)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "c = scaler.fit_transform(np.array(review['rating']).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_C. Normalize by User Ratings (Not Working Yet)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/34033785/normalize-values-in-dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "review[review['reviewer_id'] == 50853]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = review[['reviewer_id','rating']].groupby(['rating'],as_index=False).transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_D. Log Probability Distribution [NOT CORRECT]_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(9.2,4))\n",
    "plt.plot([review.rating[review.rating == i].sum()/review.rating.sum() for i in n])\n",
    "plt.title('Probability Rating Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(9.2,4))\n",
    "plt.plot(np.log([review.rating[review.rating == i].sum()/review.rating.sum() for i in n]))\n",
    "plt.title('Log Probability Rating Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Natural Language Processing Features:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Functions for finding percentage frequency (capital letters/punctuation)\n",
    "def per_check(string_value, total):\n",
    "    percentage = len(string_value)\n",
    "    if percentage != 0:\n",
    "        percentage = float(total / percentage) * 100\n",
    "    else:\n",
    "        percentage = 0\n",
    "    return percentage\n",
    "\n",
    "def punc_count(string_value):\n",
    "    count = 0\n",
    "    for c in string_value:\n",
    "        if c in punctuation:\n",
    "            count+= 1\n",
    "    return per_check(string_value, count)\n",
    "\n",
    "def caplet_count(string_value):\n",
    "    count = 0\n",
    "    for c in string_value:\n",
    "        if c.isupper():\n",
    "            count+= 1\n",
    "    return per_check(string_value, count)      \n",
    "\n",
    "review['c_len'] = review.comment.apply(len)\n",
    "review['punc_count'] = review.comment.apply(punc_count)\n",
    "review['caplet_count'] = review.comment.apply(caplet_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Spacy_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "docs = []\n",
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "deps = []\n",
    "ents = []\n",
    "sentences = []\n",
    "\n",
    "def insert_null(l):\n",
    "    return [(w if w else '0') for w in l]\n",
    "\n",
    "pipeline = nlp.pipe(review['comment'].astype('unicode').values,\n",
    "                    batch_size = 10, \n",
    "                    n_threads=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create doc\n",
    "review['doc'] = [doc if doc.is_parsed else None for doc in pipeline]\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# apply features\n",
    "review['w_len'] = review.doc.apply(len)\n",
    "review['tokens'] = review.doc.apply(lambda doc: insert_null([tok.text for tok in doc]))\n",
    "review['lemma'] = review.doc.apply(lambda doc: insert_null([tok.lemma_ for tok in doc]))\n",
    "review['pos'] = review.doc.apply(lambda doc: insert_null([tok.pos_ for tok in doc]))\n",
    "review['deps'] = review.doc.apply(lambda doc: insert_null([tok.dep_ for tok in doc]))\n",
    "review['ents'] = review.doc.apply(lambda doc: insert_null([tok.ent_type_ for tok in doc]))\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "review.c_len.max()\n",
    "print(review.comment[review.c_len == 7977].iloc[0][0:300],end=''); print('...')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _TextBlob_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "blobs = review.comment.apply(lambda val: textblob.TextBlob(val))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "review['sent_pol'] = blobs.apply(lambda val: val.sentiment[0])\n",
    "review['sent_subj'] = blobs.apply(lambda val: val.sentiment[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pol = Sentiment Polarity (positive or negative word choice)_ <br>\n",
    "_Subj = Sentiment Subjectivity (objective or subjective word choice)_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Additional Textblob Features (Not included because of Spacy)\n",
    "review['wc'] = blobs.apply(lambda val: len(val.words))\n",
    "review['sc'] = blobs.apply(lambda val: len(val.sentences))\n",
    "review['tokens'] = blobs.apply(lambda val: [w.lower() for w in val.words])\n",
    "review['pos'] = blobs.apply(lambda val: [v[1] for v in val.tags])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DataFrame With New Spacy and TextBlob Features\n",
    "review.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visuals"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def MEDIAN_reject_outliers(data, m=3):\n",
    "    data = data[abs(data - np.median(data)) < m*robust.mad(data)]\n",
    "    return data[~np.isnan(data)].sort_values()\n",
    "\n",
    "\n",
    "def MEAN_reject_outliers(data, m=3):\n",
    "    data = data[abs(data - np.mean(data)) <= m*np.std(data)]\n",
    "    return data[~np.isnan(data)].sort_values()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ratings\n",
    "plt.figure(figsize=(9.2,4))\n",
    "plt.hist(review.rating,bins=10)\n",
    "plt.title('Rating Distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(MEDIAN_reject_outliers(review.c_len))\n",
    "# plt.title('Average Char Length');\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.distplot(MEDIAN_reject_outliers(review.punc_count))\n",
    "plt.xlabel('Rating');\n",
    "plt.ylabel('Punc Percentatage');\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.scatter(review.rating,review.c_len)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Comment Length')\n",
    "xlist = []\n",
    "ylist = []\n",
    "m,b = np.polyfit(review.rating, review.c_len, 1)\n",
    "for i in range(0,11):\n",
    "    ylist.append(i*m + b)\n",
    "    xlist.append(i)\n",
    "plt.plot(xlist,ylist,color='r')\n",
    "# plt.title('Ratings by Review Len')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.scatter(review.rating,review.punc_count);\n",
    "xlist = []\n",
    "ylist = []\n",
    "m,b = np.polyfit(review.rating, review.punc_count, 1)\n",
    "for i in range(0,11):\n",
    "    ylist.append(i*m + b)\n",
    "    xlist.append(i)\n",
    "plt.plot(xlist,ylist,color='r')\n",
    "# plt.title('Ratings by Punctuation Percentage');\n",
    "plt.xlabel('Rating');\n",
    "plt.ylabel('Punct Percentage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['c_len','caplet_count','punc_count','rating','sent_pol','sent_subj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = review['rating']\n",
    "X = review[features].drop('rating',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Cluster Model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tries to find clusters in the data but doesnt predict anything_ (Not currently relevant)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Akaike Information Criterion\n",
    "2*n_features - 2*maxlikelihood_est\n",
    "\n",
    "Bayesian Information Criterion\n",
    "ln(n_samples)*n_features-2*maxlikelihood_est"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "predict = []\n",
    "for i in range(2,11):\n",
    "    # Declare and fit the model.\n",
    "    sc = SpectralClustering(n_clusters=i)\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    #Predicted clusters.\n",
    "    predict.append(sc.fit_predict(X_train))\n",
    "    \n",
    "    print('{} completed'.format(i))\n",
    "\n",
    "    \n",
    "    sc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Principal Components Analysis PCA (reduces features to 2 for visualization)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "\n",
    "X_train_pca_df = pd.DataFrame(X_train_pca)\n",
    "X_train_pca_df.columns = ['comp_1','comp_2']\n",
    "X_train_pca_df['hue'] = predict[3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot([i for i in range(1,11)],list(X_train_pca_df.hue.value_counts()),color ='b');\n",
    "plt.plot([i for i in range(1,11)],list(review.rating.value_counts()),color ='g');\n",
    "\n",
    "plt.legend(['Predicted Cluster','Actual Ratings']);\n",
    "plt.title('Cluster Prediction of Counts by Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(18,10))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(0, 9):\n",
    "    X_train_pca_df['hue'] = predict[i]\n",
    "    ax = fig.add_subplot(3, 3, i+1)\n",
    "    ax = sns.lmplot(x='comp_1',y='comp_2', hue='hue',data=X_train_pca_df,fit_reg=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(22,22));\n",
    "sns.lmplot(x='comp_1',y='comp_2', hue='hue',data=X_train_pca_df,fit_reg=False)\n",
    "plt.xlim(-250,1000)\n",
    "plt.ylim(-5,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Likelihood Function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(Y\\mid\\theta) = \\prod_i^n {p({y_i}\\mid\\theta)} $$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3 -- review.ratings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = [i for i in range(1,11)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tot_li = np.product([review.rating[review.rating == i].sum()/review.rating.sum() for i in n]);tot_li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Maximum Likelihood Function_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parameters which maximize likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikimedia.org/api/rest_v1/media/math/render/svg/9dc95691ee450e85995f5e3263600cb904323ee8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{1}{n}\\sum_i^n \\ln{p({y_i}\\mid\\theta)} $$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_li = (np.sum(np.log([review.rating[review.rating == i].sum()/review.rating.sum() for i in n])))/len(n); max_li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Logistic Regression_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Operates on probabilities_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print('Check for overfitting:')\n",
    "print(lr.score(X_train,y_train)*100)\n",
    "print('')\n",
    "# Print Model Score Estimation on Same Data\n",
    "print('Percentage of ratings guessed correctly:')\n",
    "print(lr.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Word Embedding - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Comments: 8416\n",
      "CPU times: user 2.44 s, sys: 283 ms, total: 2.72 s\n",
      "Wall time: 2.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review = pd.read_csv('../data/boardgame/boardgame-comments-english.csv').sample(frac=.01,random_state=42)\n",
    "review.columns = 'reviewer_id', 'game_id', 'rating', 'comment'\n",
    "\n",
    "# RATINGS ADJUSTMENT: ceiling >= .5 [or] floor < .5\n",
    "review['rating'] = review.rating.map(round)\n",
    "\n",
    "print('Total Comments: {}'.format(review.comment.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.87 s, sys: 16.1 ms, total: 4.88 s\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenize = lambda val: [b.lower() for b in textblob.TextBlob(val).words]\n",
    "sentences_blob = review.comment.map(tokenize)\n",
    "review['token'] = sentences_blob\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 s, sys: 35.8 ms, total: 4.87 s\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    # # load model\n",
    "    word_vec = word2vec.Word2Vec.load('full_word2vec_blob.bin')\n",
    "    vec_size = word_vec.layer1_size\n",
    "else: \n",
    "    vec_size = 50\n",
    "    word_vec = word2vec.Word2Vec(\n",
    "        sentences_blob,\n",
    "        workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "        min_count=5,  # Minimum word count threshold.\n",
    "        window=6,      # Number of words around target word to consider.\n",
    "        sg=0,          # Use CBOW because our corpus is small.\n",
    "        sample=1e-3 ,  # Penalize frequent words.\n",
    "        size=vec_size,      # Word vector length.\n",
    "        hs=1           # Use hierarchical softmax.\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    word_vec.save('full_word2vec_blob.bin')\n",
    "\n",
    "# List of words in model.\n",
    "vocab = word_vec.wv.vocab.keys()\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 308 ms, total: 1.91 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_new = np.array([.5 for i in range(0,vec_size)])\n",
    "review['vectors'] = review.token.apply(lambda val: [word_vec[w] if w in vocab else vec_new for w in val])\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('players', 0.5597009658813477)]\n",
      "[('simple', 0.7884871959686279), ('hard', 0.7558737993240356), ('difficult', 0.7427575588226318)]\n",
      "[('difficult', 0.79841548204422), ('easy', 0.7558737993240356), ('eventually', 0.6670530438423157)]\n"
     ]
    }
   ],
   "source": [
    "w1,w2,w3 = 'easy','player','good'\n",
    "print(word_vec.most_similar(positive=[w1, w2], negative=[w3], topn=1))\n",
    "\n",
    "w1 = 'easy'\n",
    "print(word_vec.wv.most_similar(positive=w1,topn=3))\n",
    "\n",
    "w1 = 'hard'\n",
    "print(word_vec.wv.most_similar(positive=w1,topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cosine Similarity Function__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cos(\\theta) = \\frac{A \\bullet B} {\\Vert A \\Vert \\Vert B \\Vert} =  \\frac{\\sum_{i=1}^n A_i B_i}{\\sqrt{ \\sum_{i=1}^n A^2} \\sqrt{ \\sum_{i=1}^n B^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Version A. Raw Code__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARD - EASY: 0.7558738589286804\n",
      "HARD - CAT: 0.13005948066711426\n",
      "EASY - CAT: 0.06505037844181061\n",
      "EASY - SIMPLE: 0.7884872555732727\n"
     ]
    }
   ],
   "source": [
    "euclidean_norm = lambda m: np.sqrt(np.array([a*a for a in m]).sum())\n",
    "def similarity_vec(a,b):\n",
    "    return (np.dot(a,b))/(euclidean_norm(a)*euclidean_norm(b))\n",
    "\n",
    "hard_easy = similarity_vec(word_vec['hard'],word_vec['easy'])\n",
    "hard_cat = similarity_vec(word_vec['hard'],word_vec['cat'])\n",
    "easy_cat = similarity_vec(word_vec['easy'],word_vec['cat'])\n",
    "easy_simple = similarity_vec(word_vec['easy'],word_vec['simple'])\n",
    "\n",
    "print('HARD - EASY: {}'.format(hard_easy))\n",
    "print('HARD - CAT: {}'.format(hard_cat))\n",
    "print('EASY - CAT: {}'.format(easy_cat))\n",
    "print('EASY - SIMPLE: {}'.format(easy_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Version B. SKLearn__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Comprehensive Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Slow Method_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "padding, max_words = [0 for i in range(0,vec_size)], 100\n",
    "review.vectors = list(keras.preprocessing.sequence.pad_sequences(review.vectors, \n",
    "                                                     maxlen=max_words, \n",
    "                                                     padding='post', \n",
    "                                                     dtype = 'float',\n",
    "                                                     truncating='post', \n",
    "                                                     value=padding))\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Fast Method_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.7 ms, sys: 2.24 ms, total: 84 ms\n",
      "Wall time: 84.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pad, max_words = [0 for i in range(0,vec_size)], 100\n",
    "def manual_pad(val):\n",
    "    empty = max_words-len(val)\n",
    "    for i in range(0,empty):\n",
    "        val.append(pad)\n",
    "    \n",
    "    return [i for i in val[0:max_words+1]]\n",
    "\n",
    "review.vectors=review.vectors.map(manual_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Create Train/Test Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jon's Code\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "# version for separated X and y arrays, X is vectorized text \n",
    "def balance_data_vec(X, y):\n",
    "    minsamples = y.shape[0]\n",
    "    ratings = list(range(1,11))\n",
    "\n",
    "    # get min number of samples per rating level: \n",
    "    #   we'll use this as our sample size for every rating level.\n",
    "    for rating in ratings:\n",
    "        sampsize = (y==rating).sum()\n",
    "        if sampsize < minsamples:\n",
    "            minsamples = sampsize\n",
    "\n",
    "    # take same number of samples for each rating level.\n",
    "    # sample randomly, create a new dataframe with all samples\n",
    "    X_bal = []\n",
    "    y_bal = []\n",
    "    for rating in ratings:\n",
    "        X_r = X['rating'==rating]\n",
    "        y_r = y[y==rating]\n",
    "        idx = list(range(X_r.shape[0]))\n",
    "        np.random.shuffle( idx )\n",
    "        \n",
    "        # create the output arrays\n",
    "        if type(X_bal) == list: \n",
    "            X_bal = X_r[idx[:minsamples],:]\n",
    "            y_bal = np.array([rating]*minsamples)\n",
    "            \n",
    "        # add samples to output arrays\n",
    "        else:\n",
    "            X_bal = vstack((X_bal, X_r[idx[:minsamples],:]))\n",
    "            y_bal = np.append(y_bal, np.array([rating]*minsamples), axis=0 )\n",
    "            \n",
    "    # shuffle all samples\n",
    "    idx = list(range(X_bal.shape[0])) \n",
    "    np.random.shuffle( idx )\n",
    "    X_bal = X_bal[idx,:]\n",
    "    y_bal = y_bal[idx]\n",
    "    \n",
    "    return X_bal, pd.Series(y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 3.8 ms, total: 132 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = review['rating']\n",
    "X = pd.DataFrame([list(i[0]) for i in review.vectors])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.astype(int).ravel(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal = X\n",
    "X_bal['rating'] = review['rating'].values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "linear scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "463797    1\n",
      "703580    1\n",
      "783793    1\n",
      "757921    1\n",
      "253621    1\n",
      "171856    1\n",
      "200077    1\n",
      "386038    1\n",
      "228108    1\n",
      "636041    1\n",
      "644977    1\n",
      "63353     1\n",
      "49097     1\n",
      "792885    1\n",
      "433881    1\n",
      "171845    1\n",
      "631019    1\n",
      "224075    1\n",
      "62091     1\n",
      "108664    1\n",
      "563899    1\n",
      "667010    1\n",
      "361055    1\n",
      "644986    1\n",
      "537277    1\n",
      "163274    1\n",
      "413789    1\n",
      "533547    1\n",
      "689177    1\n",
      "253620    1\n",
      "220955    1\n",
      "278598    1\n",
      "629537    1\n",
      "595740    1\n",
      "668610    1\n",
      "580844    1\n",
      "230695    1\n",
      "334301    1\n",
      "580829    1\n",
      "352025    1\n",
      "446387    1\n",
      "348110    1\n",
      "171864    1\n",
      "406967    1\n",
      "343120    1\n",
      "557151    1\n",
      "76113     1\n",
      "370809    1\n",
      "313355    1\n",
      "126269    1\n",
      "439028    1\n",
      "441806    1\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-d25cea269b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_bal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_bal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalance_data_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-3348089eb835>\u001b[0m in \u001b[0;36mbalance_data_vec\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# create the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mX_bal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mminsamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0my_bal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mminsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "X_bal,y_bal = balance_data_vec(X_bal,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _C - Keras Sequential NN_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.ravel()\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5638, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(vec_size,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1024)              52224     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 1,113,099\n",
      "Trainable params: 1,113,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5638 samples, validate on 2778 samples\n",
      "Epoch 1/10\n",
      "5638/5638 [==============================] - 14s 2ms/step - loss: 2.0421 - acc: 0.2504 - val_loss: 2.0009 - val_acc: 0.2603\n",
      "Epoch 2/10\n",
      "5638/5638 [==============================] - 14s 2ms/step - loss: 2.0298 - acc: 0.2691 - val_loss: 2.0170 - val_acc: 0.2891\n",
      "Epoch 3/10\n",
      "5638/5638 [==============================] - 14s 2ms/step - loss: 2.0256 - acc: 0.2731 - val_loss: 2.0363 - val_acc: 0.2801\n",
      "Epoch 4/10\n",
      "5638/5638 [==============================] - 15s 3ms/step - loss: 2.0364 - acc: 0.2728 - val_loss: 2.0593 - val_acc: 0.2577\n",
      "Epoch 5/10\n",
      "5638/5638 [==============================] - 14s 3ms/step - loss: 2.0292 - acc: 0.2726 - val_loss: 2.0183 - val_acc: 0.2991\n",
      "Epoch 6/10\n",
      "5638/5638 [==============================] - 14s 3ms/step - loss: 2.0157 - acc: 0.2824 - val_loss: 2.0870 - val_acc: 0.3006\n",
      "Epoch 7/10\n",
      "5638/5638 [==============================] - 14s 3ms/step - loss: 2.0326 - acc: 0.2921 - val_loss: 2.0827 - val_acc: 0.2855\n",
      "Epoch 8/10\n",
      "5638/5638 [==============================] - 15s 3ms/step - loss: 2.0451 - acc: 0.2896 - val_loss: 2.0514 - val_acc: 0.2815\n",
      "Epoch 9/10\n",
      "5638/5638 [==============================] - 14s 3ms/step - loss: 2.0319 - acc: 0.2886 - val_loss: 2.0848 - val_acc: 0.2865\n",
      "Epoch 10/10\n",
      "5638/5638 [==============================] - 14s 2ms/step - loss: 2.0351 - acc: 0.2905 - val_loss: 2.1667 - val_acc: 0.2671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.166683900004415\n",
      "Test accuracy: 0.2670986321630711\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jon's Code\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion(y, y_pred, title):\n",
    "    # rating levels\n",
    "    ratings = list(range(1,11))\n",
    "\n",
    "    # generate confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    # normalize matrix\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # plot matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.magma)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(ratings))\n",
    "    plt.xticks(tick_marks, ratings, rotation=45)\n",
    "    plt.yticks(tick_marks, ratings)\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual rating')\n",
    "    plt.xlabel('Predicted rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import argmax as kargmax\n",
    "y_predict = np.argmax(model.predict(X_test),axis=1)\n",
    "final_score = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(final_score,y_predict,'Check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity Visualization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = word_vec[word_vec.wv.vocab]\n",
    "graph_tsne = TSNE(n_components=2)\n",
    "result = graph_tsne.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(word_vec.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "# plt.ylim(-0.006,0.008)\n",
    "# plt.xlim(-.02,.04)\n",
    "plt.show()\n",
    "\n",
    "graph_pca = PCA(n_components=2)\n",
    "result = graph_pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(word_vec.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "# plt.ylim(-0.006,0.008)\n",
    "# plt.xlim(-.02,.04)\n",
    "plt.show()\n",
    "beep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Root Mean Squared Error_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSE_{y} =  \\sqrt{\\frac{\\sum_{i=1}^n {(\\hat{y}_{i}- y_{i})}^2}{N}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.sum(np.square(np.subtract(y_predict,y_actual)))/len(y_actual))\n",
    "# print('Root Mean Squared Error: {}'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Notes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathjacks / Tex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
