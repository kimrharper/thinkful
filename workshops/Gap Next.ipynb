{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap - Next Generation\n",
    "\n",
    "This notebook is the initiation of redesigning the Gap Computer Vision module to meet the 'bar' to be widely (globally) accepted open source frame for data engineering in computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Expections\n",
    "\n",
    "This section is covers the anticipated \"technical\" expectations:\n",
    "\n",
    "1. Continue with OOP style developer API for the targeted audience.\n",
    "2. Maintain high-speed in-memory performance as close to comparable to hard-coding.\n",
    "3. Resuse of machine learning ready data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Direction\n",
    "\n",
    "Gap Next Generation will be designed from the bottom up (storage => progress to => developer API) utilizing the lessons learned from the top-down design of the first Gap.\n",
    "\n",
    "1. On-Disk Storage\n",
    "2. Writing to and Retrieving from Storage\n",
    "3. Processing Images\n",
    "4. Transformations / Augmentation\n",
    "5. Feeding Neural Networks\n",
    "6. Collection Management\n",
    "7. Inspection / Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-Disk Storage\n",
    "\n",
    "The HDF5 file system will continue to be the basis for on-disk storage. Storage will consist of:\n",
    "1. Preprocessed images are stored as numpy arrays in HDF5 datasets.\n",
    "2. Image collections of the same classification are stored as a HDF5 group.\n",
    "3. Metadata are stored as HDF5 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HDF5 library\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Storage\n",
    "\n",
    "Preprocessed machine learning ready data for images are essentially multi-layer matrixes. Storage of matrixes are optimized in HDF5 for Python by storing as numpy arrays.\n",
    "\n",
    "Numpy arrays are continuous memory storage of bytes, and the Python numpy library is performance optimized by writing it in C with Python linkage (CPython).\n",
    "\n",
    "To maximize efficiency, the following should be considered:\n",
    "\n",
    "1. Storing individual images a separate datasets of a continuous dataset. In the later, each image (matrix) has to be the same size. Images (Matrixes) of different sizes are *not* be supported.\n",
    "\n",
    "\n",
    "2. The datatype of the storage should be indicative of the level of preprocessing:\n",
    "\n",
    "        A. uint8 - raw 8-bit pixel data  \n",
    "        B. uint16 - raw 16-bit pixel data  \n",
    "        C. float16 - normalized pixel data for half-float hardware emulation.  \n",
    "        D. float32 - normalized pixel data as standard floating point.  \n",
    "        E. emulated uint12\n",
    "    \n",
    "*Note* - Some microscopy systems use 12-bit pixels. Numpy does not natively support 12 bits. This would need to be emulated. I did a quick Google on the topic, and found blogs out there addressing how to emulate 12-bit in numpy.\n",
    "    \n",
    "    \n",
    "3. The matrix shape should be indicative of the image data type and channels. Each image has to be the same shape and number of channels. Images (Matrixes) of different shapes are *not* be supported.\n",
    "\n",
    "\n",
    "       A. 1D - flatten  \n",
    "       B. 2D - grayscale image  \n",
    "       C. 3D - color image (RGB, RGBA, CMYK)\n",
    "   \n",
    "For flatten image, the metadata would need to be accessed to know it's unflatten shape. For multi-channel data, the metadata will need to be accessed to know the channel types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 Layout\n",
    "\n",
    "The following is the HDF5 file layout for image collections that have a single classification per image.\n",
    "\n",
    "```\n",
    "hdf5 file  \n",
    "        group  \n",
    "            dataset - images have the same classification  \n",
    "                attributes - image specific attributes\n",
    "            attributes - attributes that apply to all images in the group\n",
    "        group  \n",
    "            dataset  \n",
    "                attributes\n",
    "            attributes  \n",
    "        ...  \n",
    "\n",
    "        attributes - global attributes that apply to all images (e.g., shape)\n",
    "```\n",
    "\n",
    "*Question* How to represent multi-classification images. For example, and image with several objects. We need to identify all the classes and the boundary box (segmentation) where each object (class) is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6385ca3ac638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Open an empty HDF5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gap.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "# Open an empty HDF5 file\n",
    "\n",
    "hf = h5py.File('gap.h5','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Attributes\n",
    "\n",
    "Metadata that applies to the entire dataset are stored as global (toplevel) attributes in the HDF5 file. These include:\n",
    "\n",
    "        1. Collection Name\n",
    "        2. Author\n",
    "        3. Source\n",
    "        4. Description\n",
    "        5. Date Created (ISO 8601 format)\n",
    "        6. Count (i.e., Number of Images)\n",
    "        7. Shape (i.e., Unflattened Shape of Images)\n",
    "        8. Channels (e.g., 1 = R, 2 = G, 3 = B).\n",
    "        \n",
    "##### Key Name Rules\n",
    "\n",
    "- The keys for the metadata are fully spelled out (i.e., not abbreviated). \n",
    "- Keys that combine multiple words, the words are separated by commas.\n",
    "- Keys that are plural are spelled singular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of hand setting global attributes\n",
    "hf.attrs['name'] = 'Flowers'\n",
    "hf.attrs['author'] = 'ABC Company'\n",
    "hf.attrs['source'] = 'http://....'\n",
    "hf.attrs['description'] = 'Images for classifiying types of flowers'\n",
    "hf.attrs['date'] = '2018-10-01'\n",
    "hf.attrs['count'] = 50000\n",
    "hf.attrs['shape'] = (100, 100, 3)\n",
    "hf.attrs['channel'] = str([ 'C', 'M', 'Y', 'K'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group\n",
    "\n",
    "A group is a collection of images which share the same classification (e.g., daisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of hand creating a Group\n",
    "grp_daisy     = hf.create_group(\"daisy\")\n",
    "grp_sunflower = hf.create_group(\"sunflower\")\n",
    "grp_rose      = hf.create_group(\"rose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Attributes\n",
    "\n",
    "Metadata that applies to an entire group of images, which share the same classification (label) are stored in the corresponding group's attributes. These include:\n",
    "\n",
    "        1. Label (classification)\n",
    "        2. Number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exanple of hand setting attributes for a group\n",
    "grp_daisy.attrs['label'] = 'daisy'\n",
    "grp_daisy.attrs['count'] = 663"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Dataset\n",
    "\n",
    "The machine learning ready data for an entire group of images, which are the same classification (label) are stored in the corresponding group's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy for C-like in-memory arrays\n",
    "import numpy as np\n",
    "\n",
    "# import openCV for image processing\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a collection of daisy images\n",
    "subdir = 'flower_photos/daisy'\n",
    "files = os.listdir('flower_photos/daisy')\n",
    "collection = []\n",
    "for file in files:\n",
    "    # for each image in the subfolder, read in using openCV\n",
    "    # openCV will decompress the image into a raw bitmap of pixels\n",
    "    image = cv2.imread(subdir + '/' + file)\n",
    "    image = cv2.resize(image, (50,50), interpolation=cv2.INTER_AREA)\n",
    "    # append each in-memory image into a list\n",
    "    collection.append(image)\n",
    "    \n",
    "# once the collection is assembled, convert the list to a multi-dimensional numpy array\n",
    "daises = np.asarray(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = grp_daisy.create_dataset(\"daisy\", data=daises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
