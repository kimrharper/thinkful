{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function we'll call each iteration (or step) of the gradient algorithm.\n",
    "def step (alpha_cur, beta_cur, learning_rate, x, y):\n",
    "    '''Move downhill from a current cost function to a new, more optimal one.'''\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        # Partial derivative of the intercept.\n",
    "        point_alpha = -(2/n) * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        alpha += point_alpha\n",
    "        \n",
    "        # Partial derivative of the slope.\n",
    "        point_beta = -(2 / n) * x[i] * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        beta += point_beta\n",
    "        \n",
    "    new_alpha = alpha_cur - learning_rate * alpha \n",
    "    new_beta = beta_cur - learning_rate * beta\n",
    "    return [new_alpha, new_beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial}{\\partial\\alpha} =\\frac2n \\sum_{i=1}^n - (y^i-(\\alpha + \\beta x_i) )$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\beta} =\\frac2n \\sum_{i=1}^n - x_i(y^i-(\\alpha + \\beta x_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, m_current=0, b_current=0, epochs=1000, threshold=.0001, learning_rate=0.0001):\n",
    "    N = float(len(y))\n",
    "    for i in range(epochs):\n",
    "        y_current = (m_current * X) + b_current\n",
    "        cost = sum([data**2 for data in (y-y_current)]) / N\n",
    "        m_gradient = -(2/N) * sum(X * (y - y_current))\n",
    "        b_gradient = -(2/N) * sum(y - y_current)\n",
    "        m_current = m_current - (learning_rate * m_gradient)\n",
    "        b_current = b_current - (learning_rate * b_gradient)\n",
    "    return m_current, b_current, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(range(1,11))\n",
    "y = np.log(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2586631799160805, 0.04579556239876547, 0.05397294349663465)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(X,y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "der_alpha_sum = lambda X,y,a,b: -(2/len(X))*np.sum((y-(a+b*X)))\n",
    "der_beta_sum = lambda X,y,a,b: -(2/len(X))*np.sum(X*(y-(a+b*X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha,beta,learning_rate=0,0,.1\n",
    "\n",
    "alpha = der_alpha_sum(X,y,alpha,beta)\n",
    "beta = der_beta_sum(X,y,alpha,beta)\n",
    "    \n",
    "new_a = alpha-learning_rate*alpha\n",
    "new_b = beta-learning_rate*beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-63.0, -1125.0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_a,new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_alpha = lambda X,y,a,b,n: -(2/n)*(y-(a+b*X))\n",
    "der_beta = lambda X,y,a,b,n: -(2/n)*X*(y-(a+b*X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha,beta,learning_rate=0,0,.1\n",
    "n = len(x)\n",
    "for i in range(n):\n",
    "    alpha+=der_alpha(X[i],y[i],alpha,beta,n)\n",
    "    beta+=der_beta(X[i],y[i],alpha,beta,n)\n",
    "    \n",
    "new_a = alpha-learning_rate*alpha\n",
    "new_b = beta-learning_rate*beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-26788656.668574974, -314937385.8379723)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_a,new_b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import the necessary packages\n",
    "\n",
    " \n",
    "def sigmoid_activation(x):\n",
    "    # compute and return the sigmoid activation value for a\n",
    "    # given input value\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    " \n",
    "def next_batch(X, y, batchSize):\n",
    "    # loop over our dataset `X` in mini-batches of size `batchSize`\n",
    "    for i in np.arange(0, X.shape[0], batchSize):\n",
    "        # yield a tuple of the current batched data and labels\n",
    "        yield (X[i:i + batchSize], y[i:i + batchSize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(-20,20))\n",
    "y = [df(v) for v in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] X: -6.6, Grad Descent: -1.9199999999999995, step_size: 9.6\n",
      "[2] X: -4.68, Grad Descent: 0.38400000000000034, step_size: 1.92\n",
      "[3] X: -5.064, Grad Descent: -0.07680000000000006, step_size: 0.38400000000000034\n",
      "[4] X: -4.9872, Grad Descent: 0.01536000000000044, step_size: 0.07680000000000042\n",
      "[5] X: -5.00256, Grad Descent: -0.0030719999999998747, step_size: 0.015360000000000262\n",
      "[6] X: -4.999488, Grad Descent: 0.0006143999999995486, step_size: 0.0030719999999995196\n",
      "[7] X: -5.0001024, Grad Descent: -0.00012288000000033604, step_size: 0.0006143999999999039\n",
      "[8] X: -4.99997952, Grad Descent: 2.4575999999854046e-05, step_size: 0.00012288000000015842\n",
      "[9] X: -5.000004096, Grad Descent: -4.9151999995444834e-06, step_size: 2.4575999999498777e-05\n",
      "[10] X: -4.9999991808, Grad Descent: 9.830400003352224e-07, step_size: 4.915199999899755e-06\n",
      "[11] X: -5.00000016384, Grad Descent: -1.966080002802073e-07, step_size: 9.830400005128581e-07\n",
      "The local minimum occurs at -5.00000016384\n"
     ]
    }
   ],
   "source": [
    "cur_x = 3 # The algorithm starts at x=3\n",
    "rate = 0.6 # Learning rate\n",
    "precision = 0.000001 #This tells us when to stop the algorithm\n",
    "previous_step_size = 1 #\n",
    "max_iters = 10000 # maximum number of iterations\n",
    "iters = 0 #iteration counter\n",
    "df = lambda x: 2*(x+5) #Gradient of our function \n",
    "\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x #Store current x value in prev_x\n",
    "    cur_x = cur_x - rate * df(prev_x) #Grad descent\n",
    "    previous_step_size = abs(cur_x - prev_x) #Change in x\n",
    "    iters = iters+1 #iteration count\n",
    "    print(\"[{0:}] X: {1}, Grad Descent: {2}, step_size: {3}\".format(iters,cur_x,rate *df(cur_x),previous_step_size)) #Print iterations\n",
    "    \n",
    "print(\"The local minimum occurs at\", cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of items\n",
    "# array of items\n",
    "X = np.array([1, 2.5, 3.1, 4.6, 5.9,6,7,8.1,9.6,10.4,10.7])\n",
    "N = len(X)\n",
    "p=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/.local/share/virtualenvs/thinkful-Xo17phXs/lib/python3.7/site-packages/pandas/core/series.py:3727: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  infer_datetime_format=infer_datetime_format)\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from matplotlib import pyplot\n",
    "series = Series.from_csv('../data/timeseries/daily-total-female-births-in-cal.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lagged dataset\n",
    "values = DataFrame(series.values)\n",
    "dataframe = concat([values.shift(1), values], axis=1)\n",
    "dataframe.columns = ['t-1', 't+1']\n",
    "# split into train and test sets\n",
    "X = dataframe.values\n",
    "train_size = int(len(X) * 0.66)\n",
    "train, test = X[1:train_size], X[train_size:]\n",
    "train_X, train_y = train[:,0], train[:,1]\n",
    "test_X, test_y = test[:,0], test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistence model on training set\n",
    "train_pred = [x for x in train_X]\n",
    "# calculate residuals\n",
    "train_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model the training set residuals\n",
    "model = AR(train_resid)\n",
    "model_fit = model.fit()\n",
    "window = model_fit.k_ar\n",
    "coef = model_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 1.0, -12.0, 11.0, -6.0, 8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0]\n",
      "[1.0, -12.0, 11.0, -6.0, 8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0]\n",
      "[-12.0, 11.0, -6.0, 8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0]\n",
      "[11.0, -6.0, 8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0]\n",
      "[-6.0, 8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0]\n",
      "[8.0, 0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0]\n",
      "[0.0, -6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0]\n",
      "[-6.0, -1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0]\n",
      "[-1.0, 5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0]\n",
      "[5.0, 4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0]\n",
      "[4.0, 2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0]\n",
      "[2.0, -9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0]\n",
      "[-9.0, 1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0]\n",
      "[1.0, 9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0]\n",
      "[9.0, -10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0]\n",
      "[-10.0, 3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0]\n",
      "[3.0, -6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0]\n",
      "[-6.0, 30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0]\n",
      "[30.0, -28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0]\n",
      "[-28.0, 2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0]\n",
      "[2.0, 9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0]\n",
      "[9.0, -7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0]\n",
      "[-7.0, 1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0]\n",
      "[1.0, -9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0]\n",
      "[-9.0, 21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0]\n",
      "[21.0, -13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0]\n",
      "[-13.0, -2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0]\n",
      "[-2.0, 11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0]\n",
      "[11.0, -11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0]\n",
      "[-11.0, -8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0]\n",
      "[-8.0, 6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0]\n",
      "[6.0, 16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0]\n",
      "[16.0, -12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0]\n",
      "[-12.0, 9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0]\n",
      "[9.0, 2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0]\n",
      "[2.0, -16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0]\n",
      "[-16.0, 20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0]\n",
      "[20.0, -4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0]\n",
      "[-4.0, 18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0]\n",
      "[18.0, -18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0]\n",
      "[-18.0, -11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0]\n",
      "[-11.0, -1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0]\n",
      "[-1.0, -3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0]\n",
      "[-3.0, 7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0]\n",
      "[7.0, 4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0]\n",
      "[4.0, 5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0]\n",
      "[5.0, -7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0]\n",
      "[-7.0, 5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0]\n",
      "[5.0, 2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0]\n",
      "[2.0, -9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0]\n",
      "[-9.0, -3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0]\n",
      "[-3.0, -1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0]\n",
      "[-1.0, -1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0]\n",
      "[-1.0, 3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0]\n",
      "[3.0, 5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0]\n",
      "[5.0, -2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0]\n",
      "[-2.0, -5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0]\n",
      "[-5.0, -3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0]\n",
      "[-3.0, 19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0]\n",
      "[19.0, -18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0]\n",
      "[-18.0, 1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0]\n",
      "[1.0, 9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0]\n",
      "[9.0, -2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0]\n",
      "[-2.0, -4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0]\n",
      "[-4.0, -2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0]\n",
      "[-2.0, -1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0]\n",
      "[-1.0, -4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0]\n",
      "[-4.0, 9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0]\n",
      "[9.0, -9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0]\n",
      "[-9.0, -2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0]\n",
      "[-2.0, 6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0]\n",
      "[6.0, -7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0]\n",
      "[-7.0, -7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0]\n",
      "[-7.0, 16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0]\n",
      "[16.0, -8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0]\n",
      "[-8.0, 9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0]\n",
      "[9.0, 1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0]\n",
      "[1.0, 2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0]\n",
      "[2.0, 1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0]\n",
      "[1.0, -6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0]\n",
      "[-6.0, -1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0]\n",
      "[-1.0, 17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0]\n",
      "[17.0, -14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0]\n",
      "[-14.0, 7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0]\n",
      "[7.0, -6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0]\n",
      "[-6.0, -4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0]\n",
      "[-4.0, -2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0]\n",
      "[-2.0, 0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0]\n",
      "[0.0, 5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0]\n",
      "[5.0, -10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0]\n",
      "[-10.0, 0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0]\n",
      "[0.0, 5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0]\n",
      "[5.0, -1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0]\n",
      "[-1.0, -6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0]\n",
      "[-6.0, 9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0]\n",
      "[9.0, 5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0]\n",
      "[5.0, 4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0]\n",
      "[4.0, -7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0]\n",
      "[-7.0, -4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0]\n",
      "[-4.0, 17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0]\n",
      "[17.0, -8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0]\n",
      "[-8.0, -4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0]\n",
      "[-4.0, 4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0]\n",
      "[4.0, 2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0]\n",
      "[2.0, -5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0]\n",
      "[-5.0, -2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0]\n",
      "[-2.0, 8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0]\n",
      "[8.0, -7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0]\n",
      "[-7.0, -13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0]\n",
      "[-13.0, 14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0]\n",
      "[14.0, -5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0]\n",
      "[-5.0, -7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0]\n",
      "[-7.0, -1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0]\n",
      "[-1.0, 3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0]\n",
      "[3.0, 13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0]\n",
      "[13.0, -6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0]\n",
      "[-6.0, 0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0]\n",
      "[0.0, -9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0]\n",
      "[-9.0, 5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0]\n",
      "[5.0, -4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0]\n",
      "[-4.0, 17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0, 3.0]\n",
      "[17.0, -5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0, 3.0, 15.0]\n",
      "[-5.0, 5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0, 3.0, 15.0, -4.0]\n",
      "[5.0, -13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0, 3.0, 15.0, -4.0, 7.0]\n",
      "[-13.0, 1.0, 2.0, 0.0, 11.0, -14.0, 1.0, -2.0, 6.0, -10.0, 3.0, 15.0, -4.0, 7.0, -5.0]\n"
     ]
    }
   ],
   "source": [
    "# walk forward over time steps in test\n",
    "history = train_resid[len(train_resid)-window:]\n",
    "history = [history[i] for i in range(len(history))]\n",
    "predictions = list()\n",
    "expected_error = list()\n",
    "for t in range(len(test_y)):\n",
    "    # persistence\n",
    "    yhat = test_X[t]\n",
    "    error = test_y[t] - yhat\n",
    "    expected_error.append(error)\n",
    "    \n",
    "    # predict error\n",
    "    length = len(history)\n",
    "    lag = [history[i] for i in range(length-window,length)]\n",
    "    print(lag)\n",
    "    pred_error = coef[0]\n",
    "    for d in range(window):\n",
    "        pred_error += coef[d+1] * lag[window-d-1]\n",
    "    predictions.append(pred_error)\n",
    "    history.append(error)\n",
    "    print('predicted error=%f, expected error=%f' % (pred_error, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted error=-7.083363, expected error=-10.000000\n",
      "predicted error=2.992464, expected error=3.000000\n",
      "predicted error=-0.727356, expected error=-6.000000\n",
      "predicted error=5.600624, expected error=30.000000\n",
      "predicted error=-19.877836, expected error=-28.000000\n",
      "predicted error=4.832663, expected error=2.000000\n",
      "predicted error=3.127385, expected error=9.000000\n",
      "predicted error=-5.035700, expected error=-7.000000\n",
      "predicted error=1.202267, expected error=1.000000\n",
      "predicted error=-0.221565, expected error=-9.000000\n",
      "predicted error=9.214665, expected error=21.000000\n",
      "predicted error=-7.082098, expected error=-13.000000\n",
      "predicted error=1.237418, expected error=-2.000000\n",
      "predicted error=2.737747, expected error=11.000000\n",
      "predicted error=-4.785289, expected error=-11.000000\n",
      "predicted error=2.419604, expected error=-8.000000\n",
      "predicted error=9.194064, expected error=6.000000\n",
      "predicted error=3.128481, expected error=16.000000\n",
      "predicted error=-6.620736, expected error=-12.000000\n",
      "predicted error=1.256114, expected error=9.000000\n",
      "predicted error=-7.757220, expected error=2.000000\n",
      "predicted error=-6.101305, expected error=-16.000000\n",
      "predicted error=5.156374, expected error=20.000000\n",
      "predicted error=-13.341117, expected error=-4.000000\n",
      "predicted error=-6.986576, expected error=18.000000\n",
      "predicted error=-19.689612, expected error=-18.000000\n",
      "predicted error=-4.285231, expected error=-11.000000\n",
      "predicted error=7.429164, expected error=-1.000000\n",
      "predicted error=8.047073, expected error=-3.000000\n",
      "predicted error=8.588999, expected error=7.000000\n",
      "predicted error=3.502140, expected error=4.000000\n",
      "predicted error=0.175143, expected error=5.000000\n",
      "predicted error=-1.810712, expected error=-7.000000\n",
      "predicted error=2.195945, expected error=5.000000\n",
      "predicted error=-4.638582, expected error=2.000000\n",
      "predicted error=-5.513709, expected error=-9.000000\n",
      "predicted error=-0.097991, expected error=-3.000000\n",
      "predicted error=4.734709, expected error=-1.000000\n",
      "predicted error=7.344035, expected error=-1.000000\n",
      "predicted error=9.623202, expected error=3.000000\n",
      "predicted error=5.096753, expected error=5.000000\n",
      "predicted error=-0.504312, expected error=-2.000000\n",
      "predicted error=0.452324, expected error=-5.000000\n",
      "predicted error=2.408405, expected error=-3.000000\n",
      "predicted error=5.063297, expected error=19.000000\n",
      "predicted error=-11.297764, expected error=-18.000000\n",
      "predicted error=5.011248, expected error=1.000000\n",
      "predicted error=3.918651, expected error=9.000000\n",
      "predicted error=-3.180208, expected error=-2.000000\n",
      "predicted error=-0.318580, expected error=-4.000000\n",
      "predicted error=0.945914, expected error=-2.000000\n",
      "predicted error=2.660016, expected error=-1.000000\n",
      "predicted error=4.641854, expected error=-4.000000\n",
      "predicted error=5.471846, expected error=9.000000\n",
      "predicted error=-1.860536, expected error=-9.000000\n",
      "predicted error=8.099070, expected error=-2.000000\n",
      "predicted error=7.203131, expected error=6.000000\n",
      "predicted error=1.177543, expected error=-7.000000\n",
      "predicted error=6.931435, expected error=-7.000000\n",
      "predicted error=12.259626, expected error=16.000000\n",
      "predicted error=-3.375452, expected error=-8.000000\n",
      "predicted error=4.338856, expected error=9.000000\n",
      "predicted error=-4.527956, expected error=1.000000\n",
      "predicted error=-5.349929, expected error=2.000000\n",
      "predicted error=-5.692769, expected error=1.000000\n",
      "predicted error=-8.807746, expected error=-6.000000\n",
      "predicted error=-2.529380, expected error=-1.000000\n",
      "predicted error=-0.008945, expected error=17.000000\n",
      "predicted error=-14.431715, expected error=-14.000000\n",
      "predicted error=-0.120849, expected error=7.000000\n",
      "predicted error=-5.620386, expected error=-6.000000\n",
      "predicted error=-0.141228, expected error=-4.000000\n",
      "predicted error=4.191231, expected error=-2.000000\n",
      "predicted error=3.060415, expected error=0.000000\n",
      "predicted error=5.052219, expected error=5.000000\n",
      "predicted error=1.429764, expected error=-10.000000\n",
      "predicted error=8.785605, expected error=0.000000\n",
      "predicted error=9.008174, expected error=5.000000\n",
      "predicted error=3.781247, expected error=-1.000000\n",
      "predicted error=2.723533, expected error=-6.000000\n",
      "predicted error=7.042776, expected error=9.000000\n",
      "predicted error=-1.866666, expected error=5.000000\n",
      "predicted error=-4.219164, expected error=4.000000\n",
      "predicted error=-9.101156, expected error=-7.000000\n",
      "predicted error=-2.473636, expected error=-4.000000\n",
      "predicted error=1.763542, expected error=17.000000\n",
      "predicted error=-14.001520, expected error=-8.000000\n",
      "predicted error=-5.732539, expected error=-4.000000\n",
      "predicted error=-0.751018, expected error=4.000000\n",
      "predicted error=-3.065737, expected error=2.000000\n",
      "predicted error=-4.015188, expected error=-5.000000\n",
      "predicted error=-0.437832, expected error=-2.000000\n",
      "predicted error=1.626298, expected error=8.000000\n",
      "predicted error=-3.447638, expected error=-7.000000\n",
      "predicted error=1.048645, expected error=-13.000000\n",
      "predicted error=12.189745, expected error=14.000000\n",
      "predicted error=1.120100, expected error=-5.000000\n",
      "predicted error=5.269639, expected error=-7.000000\n",
      "predicted error=9.535556, expected error=-1.000000\n",
      "predicted error=8.899951, expected error=3.000000\n",
      "predicted error=7.942838, expected error=13.000000\n",
      "predicted error=-5.874740, expected error=-6.000000\n",
      "predicted error=-2.033617, expected error=0.000000\n",
      "predicted error=-0.417081, expected error=-9.000000\n",
      "predicted error=5.958849, expected error=5.000000\n",
      "predicted error=0.386366, expected error=-4.000000\n",
      "predicted error=4.258524, expected error=17.000000\n",
      "predicted error=-9.637744, expected error=-5.000000\n",
      "predicted error=-3.739473, expected error=5.000000\n",
      "predicted error=-9.031534, expected error=-13.000000\n",
      "predicted error=2.851111, expected error=1.000000\n",
      "predicted error=1.740351, expected error=2.000000\n",
      "predicted error=-1.444414, expected error=0.000000\n",
      "predicted error=-0.500504, expected error=11.000000\n",
      "predicted error=-8.375070, expected error=-14.000000\n",
      "predicted error=5.958418, expected error=1.000000\n",
      "predicted error=4.166104, expected error=-2.000000\n",
      "predicted error=4.495928, expected error=6.000000\n",
      "predicted error=-2.054823, expected error=-10.000000\n",
      "predicted error=6.667376, expected error=3.000000\n",
      "predicted error=3.433063, expected error=15.000000\n",
      "predicted error=-7.054159, expected error=-4.000000\n",
      "predicted error=-4.200340, expected error=7.000000\n",
      "predicted error=-10.486062, expected error=-5.000000\n",
      "predicted error=-5.987368, expected error=1909.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted error\n",
    "pyplot.plot(expected_error)\n",
    "pyplot.plot(predictions, color='red')\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
